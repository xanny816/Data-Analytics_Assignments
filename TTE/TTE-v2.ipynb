{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158caee2",
   "metadata": {},
   "source": [
    "# TTE-v2: Target Trial Emulation with Clustering\n",
    "\n",
    "This notebook extends the target trial emulation framework by integrating a clustering mechanism. In this version, we:\n",
    "\n",
    "- Load and preview the dummy data\n",
    "- Apply KMeans clustering on baseline characteristics (age, x1, x2, x3) to capture latent patient subgroups\n",
    "- Estimate switching and censoring weights using logistic regression models, while adjusting for the cluster assignment\n",
    "- Combine the weights and fit an outcome model using weighted least squares (WLS) that also adjusts for clusters\n",
    "- Expand the dataset to simulate follow-up over time\n",
    "- Fit a marginal structural model (MSM) incorporating clusters\n",
    "- Generate predictions and plot the predicted survival difference over follow-up for each cluster\n",
    "\n",
    "This approach provides additional insights into potential heterogeneity in treatment effects across different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure matplotlib to display plots inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dummy Data\n",
    "\n",
    "We load the dummy data from a CSV file named `data_censored.csv`. This dataset includes patient-level data with variables such as treatment, outcome, and several covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas DataFrame\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Preview the first few rows to verify successful data load\n",
    "print(\"Data preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply Clustering on Baseline Characteristics\n",
    "\n",
    "We use the KMeans algorithm to cluster patients based on key baseline characteristics (`age`, `x1`, `x2`, and `x3`). The resulting cluster assignments are then used as an additional categorical variable (denoted as `C(cluster)`) in our subsequent regression models. This adjustment helps account for latent heterogeneity in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select baseline features for clustering\n",
    "features = data[[\"age\", \"x1\", \"x2\", \"x3\"]]\n",
    "\n",
    "# Initialize and fit the KMeans clustering algorithm\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data[\"cluster\"] = kmeans.fit_predict(features)\n",
    "\n",
    "# Check the distribution of cluster assignments\n",
    "print(\"Cluster distribution:\")\n",
    "print(data[\"cluster\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fit Switching Weight Models with Cluster Adjustment\n",
    "\n",
    "Next, we estimate the switching weights while adjusting for cluster membership. Two logistic regression models are fit:\n",
    "\n",
    "- **Numerator Model:** Predicts treatment using `age` and the cluster indicator (`C(cluster)`).\n",
    "- **Denominator Model:** Predicts treatment using `age`, `x1`, `x3`, and the cluster indicator.\n",
    "\n",
    "The switching weight is computed as the ratio of the predicted probabilities from the numerator and denominator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the switching weight models with cluster adjustment\n",
    "\n",
    "# Numerator: treatment ~ age + C(cluster)\n",
    "switch_model_numer = smf.logit(\"treatment ~ age + C(cluster)\", data=data).fit(disp=False)\n",
    "\n",
    "# Denominator: treatment ~ age + x1 + x3 + C(cluster)\n",
    "switch_model_denom = smf.logit(\"treatment ~ age + x1 + x3 + C(cluster)\", data=data).fit(disp=False)\n",
    "\n",
    "# Compute predicted probabilities for both models\n",
    "data[\"switch_prob_numer\"] = switch_model_numer.predict(data)\n",
    "data[\"switch_prob_denom\"] = switch_model_denom.predict(data)\n",
    "\n",
    "# Calculate the switching weight\n",
    "data[\"switch_weight\"] = data[\"switch_prob_numer\"] / data[\"switch_prob_denom\"]\n",
    "\n",
    "# Display a preview of the switching weights\n",
    "print(\"Switching weights preview:\")\n",
    "print(data[[\"switch_weight\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit Censoring Weight Models with Cluster Adjustment\n",
    "\n",
    "We then estimate censoring weights, again adjusting for cluster membership. Two models are fitted:\n",
    "\n",
    "- **Numerator Model:** Predicts the censoring indicator (`censored`) using `x2` and `C(cluster)`.\n",
    "- **Denominator Model:** Predicts `censored` using `x2`, `x1`, and `C(cluster)`.\n",
    "\n",
    "The censoring weight is the ratio of the predicted probabilities from these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the censoring weight models with cluster adjustment\n",
    "\n",
    "# Numerator: censored ~ x2 + C(cluster)\n",
    "censor_model_numer = smf.logit(\"censored ~ x2 + C(cluster)\", data=data).fit(disp=False)\n",
    "\n",
    "# Denominator: censored ~ x2 + x1 + C(cluster)\n",
    "censor_model_denom = smf.logit(\"censored ~ x2 + x1 + C(cluster)\", data=data).fit(disp=False)\n",
    "\n",
    "# Compute predicted probabilities for censoring\n",
    "data[\"cens_prob_numer\"] = censor_model_numer.predict(data)\n",
    "data[\"cens_prob_denom\"] = censor_model_denom.predict(data)\n",
    "\n",
    "# Calculate the censoring weight\n",
    "data[\"censor_weight\"] = data[\"cens_prob_numer\"] / data[\"cens_prob_denom\"]\n",
    "\n",
    "# Display a preview of the censoring weights\n",
    "print(\"Censoring weights preview:\")\n",
    "print(data[[\"censor_weight\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Combine Weights\n",
    "\n",
    "The overall weight for each observation is obtained by multiplying the switching weight and the censoring weight. This combined weight will be used in the outcome and MSM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the switching and censoring weights\n",
    "data[\"weight\"] = data[\"switch_weight\"] * data[\"censor_weight\"]\n",
    "\n",
    "# Display a preview of the combined weights\n",
    "print(\"Combined weights preview:\")\n",
    "print(data[[\"weight\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fit Outcome Model with Cluster Adjustment\n",
    "\n",
    "We now fit an outcome model using weighted least squares (WLS). In addition to treatment and `x2`, we adjust for cluster membership using `C(cluster)`. This model estimates the effect of treatment on the outcome while controlling for cluster differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the outcome model using WLS with cluster adjustment\n",
    "outcome_model = smf.wls(\"outcome ~ treatment + x2 + C(cluster)\", data=data, weights=data[\"weight\"]).fit()\n",
    "\n",
    "# Print the model coefficients\n",
    "print(\"\\nSimplified Outcome Model Coefficients with Clustering:\")\n",
    "print(outcome_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Expand Data for Follow-Up\n",
    "\n",
    "To simulate follow-up over time, we expand the dataset by creating copies for follow-up times 0 to 10. This process mimics the sequential trial design where each patient is observed over multiple time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define follow-up times from 0 to 10\n",
    "followup_times = np.arange(0, 11)\n",
    "\n",
    "# Expand the dataset by creating copies of the data for each follow-up time\n",
    "expanded = pd.concat([data.assign(followup_time=t) for t in followup_times], ignore_index=True)\n",
    "\n",
    "# Preview the expanded dataset\n",
    "print(\"Expanded data preview:\")\n",
    "print(expanded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fit a Marginal Structural Model (MSM) Including Cluster as a Factor\n",
    "\n",
    "Using the expanded data, we fit a marginal structural model (MSM) via weighted least squares. In this model, we include treatment, follow-up time, `x2`, and the cluster factor (`C(cluster)`). This model helps us understand the causal effect of treatment over time while accounting for cluster-level differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MSM using the expanded dataset with cluster adjustment\n",
    "msm_model = smf.wls(\"outcome ~ treatment + followup_time + x2 + C(cluster)\", data=expanded, weights=expanded[\"weight\"]).fit()\n",
    "\n",
    "# Print the MSM model coefficients\n",
    "print(\"\\nSimplified MSM Model Coefficients with Clustering:\")\n",
    "print(msm_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Predict and Plot Outcomes Over Follow-Up by Cluster\n",
    "\n",
    "We now generate predictions for each follow-up time and plot the estimated survival difference separately for each cluster. For each cluster, the predicted outcome is computed as a weighted average, and dummy confidence intervals (±0.1) are added for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction follow-up times\n",
    "pred_times = np.arange(0, 11)\n",
    "\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Loop over each unique cluster to generate and plot predictions\n",
    "for cl in sorted(data[\"cluster\"].unique()):\n",
    "    # Filter data for the current cluster\n",
    "    cluster_data = data[data[\"cluster\"] == cl]\n",
    "    predictions = []\n",
    "    \n",
    "    # Loop through each follow-up time\n",
    "    for t in pred_times:\n",
    "        temp = cluster_data.copy()\n",
    "        temp[\"followup_time\"] = t\n",
    "        \n",
    "        # Predict outcomes using the MSM\n",
    "        pred = msm_model.predict(temp)\n",
    "        \n",
    "        # Calculate the weighted average prediction for this follow-up time\n",
    "        predictions.append(np.average(pred, weights=temp[\"weight\"]))\n",
    "    \n",
    "    # Create dummy lower and upper bounds (±0.1) for demonstration\n",
    "    lower_bound = [p - 0.1 for p in predictions]\n",
    "    upper_bound = [p + 0.1 for p in predictions]\n",
    "    \n",
    "    # Plot the predictions and confidence interval bounds for the current cluster\n",
    "    plt.plot(pred_times, predictions, label=f\"Cluster {cl}\")\n",
    "    plt.plot(pred_times, lower_bound, \"r--\")\n",
    "    plt.plot(pred_times, upper_bound, \"r--\")\n",
    "\n",
    "# Add labels, title, and legend to the plot\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Difference\")\n",
    "plt.title(\"Predicted Survival Difference Over Follow-up by Cluster\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
